\relax 
\citation{wei2024non}
\citation{bellalta2025performance}
\citation{mnih2013playing,mnih2015human}
\citation{wei2024optimized}
\citation{mnih2013playing}
\citation{sutton2018reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{1}{}\protected@file@percent }
\citation{sutton1999between}
\@writefile{toc}{\contentsline {section}{\numberline {III}System Model and Problem Formulation}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Network Architecture and System Model}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}State Space Design}{2}{}\protected@file@percent }
\newlabel{eq:state_vector}{{1}{2}}
\newlabel{eq:state_normalization}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Action Space Formulation}{2}{}\protected@file@percent }
\newlabel{eq:action_space}{{3}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Reward Function Design}{2}{}\protected@file@percent }
\newlabel{eq:reward_function}{{4}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Proposed DRL Framework}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Semi-MDP Learner Architecture}{2}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Simulation and DQN Configuration Parameters}}{3}{}\protected@file@percent }
\newlabel{tab:simulation_params}{{I}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Semi-MDP Training Algorithm}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Simulation Results}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Experimental Setup}{3}{}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Semi-MDP Training for NPCA Decision Making}}{3}{}\protected@file@percent }
\newlabel{alg:semi_mdp_npca}{{1}{3}}
\bibstyle{IEEEtran}
\bibdata{npca_references}
\bibcite{wei2024non}{1}
\bibcite{bellalta2025performance}{2}
\bibcite{mnih2013playing}{3}
\bibcite{mnih2015human}{4}
\bibcite{wei2024optimized}{5}
\bibcite{sutton2018reinforcement}{6}
\bibcite{sutton1999between}{7}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training convergence showing episode rewards over time for DRL-based NPCA learning in different network densities.}}{4}{}\protected@file@percent }
\newlabel{fig:training_convergence}{{1}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Policy comparison under varying PPDU durations for DRL-based NPCA learning with 10 STAs each channel.}}{4}{}\protected@file@percent }
\newlabel{fig:policy_comparison}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Training Convergence}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Performance Analysis}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion and Future Work}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{4}{}\protected@file@percent }
\gdef \@abspage@last{4}
