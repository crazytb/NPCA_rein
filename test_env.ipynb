{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6f8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPCA Environment í…ŒìŠ¤íŠ¸ ì‹œìž‘\n",
      "1. í™˜ê²½ ìƒì„± í…ŒìŠ¤íŠ¸\n",
      "Action space: Discrete(2)\n",
      "Observation space: Dict('can_finish_before_obss': Discrete(2), 'current_backoff': Box(0.0, 1.0, (1,), float32), 'cw_index': Box(0.0, 1.0, (1,), float32), 'npca_intra_busy': Discrete(2), 'npca_obss_remain': Box(0.0, 1.0, (1,), float32), 'ppdu_duration': Box(0.0, 1.0, (1,), float32), 'primary_intra_busy': Discrete(2), 'primary_obss_remain': Box(0.0, 1.0, (1,), float32), 'recent_success_rate': Box(0.0, 1.0, (1,), float32))\n",
      "2. Reset í…ŒìŠ¤íŠ¸\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. Reset í…ŒìŠ¤íŠ¸\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m obs, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial observation shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial observation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInfo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# test_npca_env.ipynb\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# drl_framework ê²½ë¡œ ì¶”ê°€\n",
    "sys.path.append('drl_framework')\n",
    "from NPCAEnv import NPCAEnv, make_npca_env\n",
    "\n",
    "print(\"NPCA Environment í…ŒìŠ¤íŠ¸ ì‹œìž‘\")\n",
    "\n",
    "# %%\n",
    "# ê¸°ë³¸ í™˜ê²½ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "print(\"1. í™˜ê²½ ìƒì„± í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "env = NPCAEnv(\n",
    "    max_ppdu_duration=50,\n",
    "    max_obss_duration=100,\n",
    "    max_backoff=1024,\n",
    "    max_cw_index=6,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Action space: {env.action_space}\")\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "\n",
    "# %%\n",
    "# Reset í…ŒìŠ¤íŠ¸\n",
    "print(\"2. Reset í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "obs, info = env.reset()\n",
    "print(f\"Initial observation shape: {obs.shape}\")\n",
    "print(f\"Initial observation: {obs}\")\n",
    "print(f\"Info: {info}\")\n",
    "\n",
    "# ê´€ì°°ê°’ í•´ì„ (Dict í˜•íƒœ)\n",
    "print(\"\\nê´€ì°°ê°’ í•´ì„:\")\n",
    "print(f\"Primary OBSS remain: {obs['primary_obss_remain'][0]:.3f} (ì‹¤ì œ: {int(obs['primary_obss_remain'][0] * env.max_obss_duration)})\")\n",
    "print(f\"Primary intra busy: {obs['primary_intra_busy']}\")\n",
    "print(f\"NPCA intra busy: {obs['npca_intra_busy']}\")\n",
    "print(f\"NPCA OBSS remain: {obs['npca_obss_remain'][0]:.3f} (ì‹¤ì œ: {int(obs['npca_obss_remain'][0] * env.max_obss_duration)})\")\n",
    "print(f\"Current backoff: {obs['current_backoff'][0]:.3f} (ì‹¤ì œ: {int(obs['current_backoff'][0] * env.max_backoff)})\")\n",
    "print(f\"CW index: {obs['cw_index'][0]:.3f} (ì‹¤ì œ: {int(obs['cw_index'][0] * env.max_cw_index)})\")\n",
    "print(f\"Success rate: {obs['recent_success_rate'][0]:.3f}\")\n",
    "print(f\"PPDU duration: {obs['ppdu_duration'][0]:.3f} (ì‹¤ì œ: {int(obs['ppdu_duration'][0] * env.max_ppdu_duration)})\")\n",
    "print(f\"Can finish before OBSS: {obs['can_finish_before_obss']}\")\n",
    "\n",
    "# %%\n",
    "# Step í…ŒìŠ¤íŠ¸ - ì—¬ëŸ¬ í–‰ë™ ì‹œë„\n",
    "print(\"3. Step í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "actions = [0, 1, 0, 1, 1]  # PRIMARY ëŒ€ê¸°, NPCA ì‚¬ìš© ë“±\n",
    "rewards = []\n",
    "observations = []\n",
    "\n",
    "for i, action in enumerate(actions):\n",
    "    print(f\"\\n--- Step {i+1}: Action {action} ({'PRIMARY ëŒ€ê¸°' if action == 0 else 'NPCA ì‚¬ìš©'}) ---\")\n",
    "    \n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    observations.append(obs.copy())\n",
    "    \n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}, Truncated: {truncated}\")\n",
    "    print(f\"PPDU duration: {int(obs['ppdu_duration'][0] * env.max_ppdu_duration)}\")\n",
    "    print(f\"Primary OBSS remain: {int(obs['primary_obss_remain'][0] * env.max_obss_duration)}\")\n",
    "    print(f\"Can finish before OBSS: {bool(obs['can_finish_before_obss'])}\")\n",
    "    \n",
    "    if done or truncated:\n",
    "        print(\"Episode ended\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nì´ ë³´ìƒ: {sum(rewards)}\")\n",
    "\n",
    "# %%\n",
    "# ëžœë¤ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ (ë” ê¸´ ì—í”¼ì†Œë“œ)\n",
    "print(\"4. ëžœë¤ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "np.random.seed(42)\n",
    "env.reset(seed=42)\n",
    "\n",
    "episode_rewards = []\n",
    "episode_actions = []\n",
    "episode_ppdu_durations = []\n",
    "total_reward = 0\n",
    "steps = 0\n",
    "\n",
    "for step in range(50):  # 50ìŠ¤í… ì‹¤í–‰\n",
    "    # ëžœë¤ í–‰ë™ ì„ íƒ\n",
    "    action = np.random.choice([0, 1])\n",
    "    \n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    episode_rewards.append(reward)\n",
    "    episode_actions.append(action)\n",
    "    episode_ppdu_durations.append(int(obs['ppdu_duration'][0] * env.max_ppdu_duration))\n",
    "    total_reward += reward\n",
    "    steps += 1\n",
    "    \n",
    "    if done or truncated:\n",
    "        break\n",
    "\n",
    "print(f\"ì—í”¼ì†Œë“œ ì™„ë£Œ: {steps} ìŠ¤í…\")\n",
    "print(f\"ì´ ë³´ìƒ: {total_reward}\")\n",
    "print(f\"í‰ê·  ë³´ìƒ: {total_reward/steps:.2f}\")\n",
    "\n",
    "# í–‰ë™ ë¶„ì„\n",
    "action_counts = {0: episode_actions.count(0), 1: episode_actions.count(1)}\n",
    "print(f\"í–‰ë™ ë¶„í¬: PRIMARY ëŒ€ê¸° {action_counts[0]}íšŒ, NPCA ì‚¬ìš© {action_counts[1]}íšŒ\")\n",
    "\n",
    "# %%\n",
    "# ì‹œê°í™”\n",
    "print(\"5. ê²°ê³¼ ì‹œê°í™”\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# ë³´ìƒ ì‹œê³„ì—´\n",
    "axes[0,0].plot(episode_rewards)\n",
    "axes[0,0].set_title('Episode Rewards')\n",
    "axes[0,0].set_xlabel('Step')\n",
    "axes[0,0].set_ylabel('Reward')\n",
    "axes[0,0].grid(True)\n",
    "\n",
    "# í–‰ë™ ì‹œê³„ì—´\n",
    "axes[0,1].plot(episode_actions, 'o-', alpha=0.7)\n",
    "axes[0,1].set_title('Actions (0=PRIMARY, 1=NPCA)')\n",
    "axes[0,1].set_xlabel('Step')\n",
    "axes[0,1].set_ylabel('Action')\n",
    "axes[0,1].set_ylim(-0.1, 1.1)\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "# PPDU duration ë¶„í¬\n",
    "axes[1,0].hist(episode_ppdu_durations, bins=10, alpha=0.7)\n",
    "axes[1,0].set_title('PPDU Duration Distribution')\n",
    "axes[1,0].set_xlabel('PPDU Duration')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].grid(True)\n",
    "\n",
    "# í–‰ë™ë³„ í‰ê·  ë³´ìƒ\n",
    "action_rewards = {0: [], 1: []}\n",
    "for action, reward in zip(episode_actions, episode_rewards):\n",
    "    action_rewards[action].append(reward)\n",
    "\n",
    "avg_rewards = [np.mean(action_rewards[0]) if action_rewards[0] else 0,\n",
    "               np.mean(action_rewards[1]) if action_rewards[1] else 0]\n",
    "\n",
    "axes[1,1].bar(['PRIMARY', 'NPCA'], avg_rewards, alpha=0.7)\n",
    "axes[1,1].set_title('Average Reward by Action')\n",
    "axes[1,1].set_ylabel('Average Reward')\n",
    "axes[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# í™˜ê²½ íŒŒë¼ë¯¸í„°ë³„ í…ŒìŠ¤íŠ¸\n",
    "print(\"6. í™˜ê²½ íŒŒë¼ë¯¸í„° ì˜í–¥ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "# ë‹¤ì–‘í•œ OBSS generation rateë¡œ í…ŒìŠ¤íŠ¸\n",
    "obss_rates = [0.05, 0.1, 0.2, 0.3]\n",
    "results = {}\n",
    "\n",
    "for rate in obss_rates:\n",
    "    print(f\"\\nOBSS generation rate: {rate}\")\n",
    "    \n",
    "    # í™˜ê²½ ìž¬ìƒì„± (ì‹¤ì œë¡œëŠ” ë™ì ìœ¼ë¡œ ë°”ê¿€ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì‹œë®¬ë ˆì´ì…˜)\n",
    "    env_test = NPCAEnv(max_obss_duration=100, seed=42)\n",
    "    \n",
    "    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "    env_test.reset()\n",
    "    test_rewards = []\n",
    "    \n",
    "    for _ in range(20):\n",
    "        # OBSS ìƒí™©ì„ ì¸ìœ„ì ìœ¼ë¡œ ë§Œë“¤ê¸°\n",
    "        env_test.primary_obss_remain = max(1, int(np.random.exponential(1/rate) * 10))\n",
    "        \n",
    "        action = np.random.choice([0, 1])\n",
    "        obs, reward, done, truncated, info = env_test.step(action)\n",
    "        test_rewards.append(reward)\n",
    "        \n",
    "        if done or truncated:\n",
    "            break\n",
    "    \n",
    "    results[rate] = {\n",
    "        'avg_reward': np.mean(test_rewards),\n",
    "        'total_reward': np.sum(test_rewards),\n",
    "        'steps': len(test_rewards)\n",
    "    }\n",
    "    \n",
    "    print(f\"  í‰ê·  ë³´ìƒ: {results[rate]['avg_reward']:.2f}\")\n",
    "    print(f\"  ì´ ë³´ìƒ: {results[rate]['total_reward']:.2f}\")\n",
    "\n",
    "# %%\n",
    "print(\"7. í™˜ê²½ ì •ìƒì„± ê²€ì¦\")\n",
    "\n",
    "# ìƒíƒœ ê³µê°„ ë²”ìœ„ í™•ì¸\n",
    "print(\"ìƒíƒœ ê³µê°„ ê²€ì¦:\")\n",
    "for _ in range(10):\n",
    "    obs, _ = env.reset()\n",
    "    # Dict í˜•íƒœì˜ ê´€ì°°ê°’ ê²€ì¦\n",
    "    for key, value in obs.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            assert np.all(value >= 0.0) and np.all(value <= 1.0), f\"{key}ê°€ [0,1] ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨: {value}\"\n",
    "        elif key in ['primary_intra_busy', 'npca_intra_busy', 'can_finish_before_obss']:\n",
    "            assert value in [0, 1], f\"{key}ê°€ 0 ë˜ëŠ” 1ì´ ì•„ë‹˜: {value}\"\n",
    "\n",
    "print(\"âœ“ ëª¨ë“  ê´€ì°°ê°’ì´ ì˜¬ë°”ë¥¸ ë²”ìœ„ ë‚´ì— ìžˆìŒ\")\n",
    "\n",
    "# í–‰ë™ ê³µê°„ í™•ì¸\n",
    "print(\"\\ní–‰ë™ ê³µê°„ ê²€ì¦:\")\n",
    "valid_actions = [0, 1]\n",
    "for action in valid_actions:\n",
    "    try:\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        print(f\"âœ“ Action {action} ì •ìƒ ë™ìž‘\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Action {action} ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ë³´ìƒ ë²”ìœ„ í™•ì¸\n",
    "print(\"\\në³´ìƒ ë²”ìœ„ ê²€ì¦:\")\n",
    "env.reset()\n",
    "rewards_sample = []\n",
    "for _ in range(100):\n",
    "    action = np.random.choice([0, 1])\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    rewards_sample.append(reward)\n",
    "\n",
    "print(f\"ë³´ìƒ ë²”ìœ„: {min(rewards_sample):.2f} ~ {max(rewards_sample):.2f}\")\n",
    "print(f\"í‰ê·  ë³´ìƒ: {np.mean(rewards_sample):.2f}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ NPCAEnv ê¸°ë³¸ ë™ìž‘ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
