#!/usr/bin/env python3
"""
ì œì•ˆê¸°ë²•(DRL) vs Always NPCA vs Always Primary ì¢…í•© ë¹„êµ
"""

import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from drl_framework.random_access import Channel, STA, Simulator
from drl_framework.train import SemiMDPLearner

def test_strategy(strategy_name, channels, stas_config, num_episodes=50, device="cpu", model_path=None):
    """ë‹¨ì¼ ì „ëµ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print(f"\n{strategy_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    episode_rewards = []
    decision_log = []
    occupancy_times = []
    
    # DRL ì •ì±…ì¸ ê²½ìš° ëª¨ë¸ ë¡œë“œ
    learner = None
    if strategy_name == "DRL Policy" and model_path and os.path.exists(model_path):
        checkpoint = torch.load(model_path, map_location=device)
        learner = SemiMDPLearner(n_observations=4, n_actions=2, device=device)
        learner.policy_net.load_state_dict(checkpoint['policy_net_state_dict'])
        learner.target_net.load_state_dict(checkpoint['target_net_state_dict'])
        learner.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        learner.steps_done = checkpoint['steps_done']
        learner.policy_net.eval()
    
    for episode in range(num_episodes):
        if episode % 10 == 0:
            print(f"  Episode {episode}/{num_episodes}")
        
        # ìƒˆë¡œìš´ ì±„ë„ ì¸ìŠ¤í„´ìŠ¤ (ê° ì—í”¼ì†Œë“œë§ˆë‹¤ ë…ë¦½ì ì¸ OBSS íŒ¨í„´)
        episode_channels = [
            Channel(channel_id=0, obss_generation_rate=channels[0].obss_generation_rate),
            Channel(channel_id=1, obss_generation_rate=channels[1].obss_generation_rate, 
                   obss_duration_range=channels[1].obss_duration_range)
        ]
        
        # STA ìƒì„±
        stas = []
        for config in stas_config:
            sta = STA(
                sta_id=config["sta_id"],
                channel_id=config["channel_id"],
                primary_channel=episode_channels[config["channel_id"]],
                npca_channel=episode_channels[0] if config["channel_id"] == 1 else None,
                npca_enabled=config.get("npca_enabled", False),
                radio_transition_time=config.get("radio_transition_time", 1),
                ppdu_duration=config.get("ppdu_duration", 33),
                learner=learner
            )
            
            # ê³ ì • ì „ëµ ì„¤ì •
            if strategy_name == "Always NPCA":
                sta._fixed_action = 1
            elif strategy_name == "Always Primary":
                sta._fixed_action = 0
            
            sta.decision_log = decision_log
            sta.current_episode = episode
            stas.append(sta)
        
        # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        simulator = Simulator(num_slots=200, channels=episode_channels, stas=stas)
        if learner:
            simulator.memory = learner.memory
            simulator.device = device
        simulator.run()
        
        # ê²°ê³¼ ìˆ˜ì§‘
        total_reward = sum(sta.episode_reward for sta in stas)
        total_occupancy = sum(sta.channel_occupancy_time for sta in stas)
        
        episode_rewards.append(total_reward)
        occupancy_times.append(total_occupancy)
    
    return {
        'rewards': episode_rewards,
        'occupancy_times': occupancy_times,
        'decisions': decision_log,
        'mean_reward': np.mean(episode_rewards),
        'std_reward': np.std(episode_rewards),
        'mean_occupancy': np.mean(occupancy_times),
        'success_rate': (np.array(episode_rewards) > 0).mean() * 100
    }

def run_comprehensive_comparison():
    """ì¢…í•© ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰"""
    print("="*80)
    print("ì œì•ˆê¸°ë²•(DRL) vs Always NPCA vs Always Primary ì¢…í•© ë¹„êµ")
    print("="*80)
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model_path = "./semi_mdp_results/semi_mdp_model.pth"
    num_episodes = 100
    
    # ì±„ë„ ì„¤ì • (ë†’ì€ ê°„ì„­ í™˜ê²½)
    channels = [
        Channel(channel_id=0, obss_generation_rate=0),  # NPCA channel
        Channel(channel_id=1, obss_generation_rate=0.6, obss_duration_range=(80, 150))  # Primary channel
    ]
    
    # STA ì„¤ì • (10ê°œ STA)
    stas_config = []
    for i in range(10):
        stas_config.append({
            "sta_id": i,
            "channel_id": 1,
            "npca_enabled": True,
            "ppdu_duration": 33,
            "radio_transition_time": 1
        })
    
    print(f"í…ŒìŠ¤íŠ¸ ì„¤ì •:")
    print(f"  Device: {device}")
    print(f"  Episodes: {num_episodes}")
    print(f"  STAs: {len(stas_config)}")
    print(f"  OBSS rate: {channels[1].obss_generation_rate}")
    print(f"  OBSS duration: {channels[1].obss_duration_range}")
    print(f"  Episode length: 200 slots")
    
    # ì„¸ ê°€ì§€ ì „ëµ í…ŒìŠ¤íŠ¸
    strategies = [
        ("DRL Policy (ì œì•ˆê¸°ë²•)", channels, model_path),
        ("Always NPCA", channels, None),
        ("Always Primary", channels, None)
    ]
    
    results = {}
    
    for strategy_name, test_channels, model in strategies:
        result = test_strategy(
            strategy_name, test_channels, stas_config, 
            num_episodes, device, model
        )
        results[strategy_name] = result
    
    return results, channels, stas_config

def save_results_and_plots(results, save_dir="./comprehensive_results"):
    """ê²°ê³¼ ì €ì¥ ë° í”Œë¡¯ ìƒì„±"""
    os.makedirs(save_dir, exist_ok=True)
    
    # 1. CSV íŒŒì¼ ì €ì¥
    df_data = {}
    for name, data in results.items():
        df_data[f"{name}_reward"] = data['rewards']
        df_data[f"{name}_occupancy"] = data['occupancy_times']
    
    # ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´ íŒ¨ë”©
    max_length = max(len(data['rewards']) for data in results.values())
    for key in df_data:
        if len(df_data[key]) < max_length:
            df_data[key].extend([np.nan] * (max_length - len(df_data[key])))
    
    df = pd.DataFrame(df_data)
    df.to_csv(f"{save_dir}/comparison_results.csv", index=False)
    
    # 2. í†µê³„ ìš”ì•½ ì €ì¥
    summary_data = []
    for name, data in results.items():
        summary_data.append({
            'Strategy': name,
            'Mean_Reward_%': data['mean_reward'],
            'Std_Reward_%': data['std_reward'],
            'Mean_Occupancy_slots': data['mean_occupancy'],
            'Success_Rate_%': data['success_rate'],
            'Episodes': len(data['rewards'])
        })
    
    summary_df = pd.DataFrame(summary_data)
    summary_df.to_csv(f"{save_dir}/performance_summary.csv", index=False)
    
    # 3. ìƒì„¸ í”Œë¡¯ ìƒì„±
    create_detailed_plots(results, save_dir)
    
    print(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_dir}/")

def create_detailed_plots(results, save_dir):
    """ìƒì„¸ í”Œë¡¯ ìƒì„±"""
    plt.style.use('default')
    
    # ìƒ‰ìƒ ì„¤ì •
    colors = {
        'DRL Policy (ì œì•ˆê¸°ë²•)': '#2E86AB',
        'Always NPCA': '#A23B72', 
        'Always Primary': '#F18F01'
    }
    
    # í° í”Œë¡¯ ìƒì„± (3x2 ë ˆì´ì•„ì›ƒ)
    fig = plt.figure(figsize=(18, 12))
    
    # 1. ì—í”¼ì†Œë“œë³„ ì ìœ ìœ¨
    plt.subplot(3, 2, 1)
    for name, data in results.items():
        episodes = range(len(data['rewards']))
        plt.plot(episodes, data['rewards'], label=name, alpha=0.7, 
                color=colors.get(name, 'gray'), linewidth=1)
    plt.title('Episode Occupancy Rate (%)', fontsize=12, fontweight='bold')
    plt.xlabel('Episode')
    plt.ylabel('Occupancy Rate (%)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 2. Running Average (window=20)
    plt.subplot(3, 2, 2)
    window = 20
    for name, data in results.items():
        rewards = data['rewards']
        running_avg = [np.mean(rewards[max(0, i-window+1):i+1]) for i in range(len(rewards))]
        plt.plot(running_avg, label=name, linewidth=2.5, color=colors.get(name, 'gray'))
    plt.title(f'Running Average (window={window})', fontsize=12, fontweight='bold')
    plt.xlabel('Episode')
    plt.ylabel('Average Occupancy Rate (%)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 3. ë°•ìŠ¤í”Œë¡¯
    plt.subplot(3, 2, 3)
    data_list = [results[name]['rewards'] for name in results.keys()]
    labels = [name.replace(' (ì œì•ˆê¸°ë²•)', '\n(ì œì•ˆê¸°ë²•)') for name in results.keys()]
    bp = plt.boxplot(data_list, labels=labels, patch_artist=True)
    
    for i, (patch, label) in enumerate(zip(bp['boxes'], results.keys())):
        patch.set_facecolor(colors.get(label, 'lightblue'))
        patch.set_alpha(0.7)
    
    plt.title('Occupancy Rate Distribution', fontsize=12, fontweight='bold')
    plt.ylabel('Occupancy Rate (%)')
    plt.grid(True, alpha=0.3, axis='y')
    
    # 4. ì„±ëŠ¥ ë¹„êµ ë§‰ëŒ€ê·¸ë˜í”„
    plt.subplot(3, 2, 4)
    names = [name.replace(' (ì œì•ˆê¸°ë²•)', '\n(ì œì•ˆê¸°ë²•)') for name in results.keys()]
    means = [results[name]['mean_reward'] for name in results.keys()]
    stds = [results[name]['std_reward'] for name in results.keys()]
    
    bars = plt.bar(names, means, yerr=stds, capsize=8, 
                  color=[colors.get(name, 'lightblue') for name in results.keys()],
                  alpha=0.8, edgecolor='black', linewidth=1)
    
    plt.title('Average Performance Comparison', fontsize=12, fontweight='bold')
    plt.ylabel('Mean Occupancy Rate (%)')
    plt.grid(True, alpha=0.3, axis='y')
    
    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for bar, mean in zip(bars, means):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                f'{mean:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=10)
    
    # 5. ì„±ê³µë¥  ë¹„êµ
    plt.subplot(3, 2, 5)
    success_rates = [results[name]['success_rate'] for name in results.keys()]
    bars = plt.bar(names, success_rates, 
                  color=[colors.get(name, 'lightblue') for name in results.keys()],
                  alpha=0.8, edgecolor='black', linewidth=1)
    plt.title('Success Rate Comparison', fontsize=12, fontweight='bold')
    plt.ylabel('Episodes with Occupancy > 0 (%)')
    plt.ylim(0, 105)
    plt.grid(True, alpha=0.3, axis='y')
    
    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for bar, rate in zip(bars, success_rates):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=10)
    
    # 6. ì´ ì ìœ  ì‹œê°„ ë¹„êµ
    plt.subplot(3, 2, 6)
    occupancy_means = [results[name]['mean_occupancy'] for name in results.keys()]
    bars = plt.bar(names, occupancy_means,
                  color=[colors.get(name, 'lightblue') for name in results.keys()],
                  alpha=0.8, edgecolor='black', linewidth=1)
    plt.title('Average Total Occupancy Time', fontsize=12, fontweight='bold')
    plt.ylabel('Total Occupancy (slots)')
    plt.grid(True, alpha=0.3, axis='y')
    
    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for bar, occ in zip(bars, occupancy_means):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, 
                f'{occ:.0f}', ha='center', va='bottom', fontweight='bold', fontsize=10)
    
    plt.tight_layout()
    plt.savefig(f"{save_dir}/comprehensive_comparison.png", dpi=300, bbox_inches='tight')
    plt.show()

def print_detailed_results(results):
    """ìƒì„¸ ê²°ê³¼ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ìƒì„¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
    print("="*80)
    
    for name, data in results.items():
        print(f"\nğŸ“Š {name}:")
        print(f"   í‰ê·  ì ìœ ìœ¨: {data['mean_reward']:.2f}% (Â±{data['std_reward']:.2f})")
        print(f"   í‰ê·  ì ìœ  ì‹œê°„: {data['mean_occupancy']:.1f} slots")
        print(f"   ì„±ê³µë¥ : {data['success_rate']:.1f}%")
        print(f"   ìµœëŒ€ ì ìœ ìœ¨: {max(data['rewards']):.1f}%")
        print(f"   ìµœì†Œ ì ìœ ìœ¨: {min(data['rewards']):.1f}%")
    
    # ìƒëŒ€ ì„±ëŠ¥ ë¹„êµ
    print(f"\n" + "="*50)
    print("ìƒëŒ€ ì„±ëŠ¥ ë¹„êµ")
    print("="*50)
    
    drl_mean = results['DRL Policy (ì œì•ˆê¸°ë²•)']['mean_reward']
    npca_mean = results['Always NPCA']['mean_reward']
    primary_mean = results['Always Primary']['mean_reward']
    
    if npca_mean > 0:
        drl_vs_npca = ((drl_mean - npca_mean) / npca_mean) * 100
        print(f"ì œì•ˆê¸°ë²• vs Always NPCA: {drl_vs_npca:+.1f}%")
    
    if primary_mean > 0:
        drl_vs_primary = ((drl_mean - primary_mean) / primary_mean) * 100
        print(f"ì œì•ˆê¸°ë²• vs Always Primary: {drl_vs_primary:+.1f}%")
    else:
        print(f"ì œì•ˆê¸°ë²• vs Always Primary: +âˆ% (Always Primary = 0%)")
    
    if npca_mean > 0 and primary_mean > 0:
        npca_vs_primary = ((npca_mean - primary_mean) / primary_mean) * 100
        print(f"Always NPCA vs Always Primary: {npca_vs_primary:+.1f}%")
    
    # ìµœê³  ì„±ëŠ¥ ì „ëµ
    best_strategy = max(results.keys(), key=lambda k: results[k]['mean_reward'])
    best_mean = results[best_strategy]['mean_reward']
    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_strategy} ({best_mean:.2f}% ì ìœ ìœ¨)")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì¢…í•© ë¹„êµ ì‹¤í–‰
    results, channels, stas_config = run_comprehensive_comparison()
    
    # ê²°ê³¼ ì €ì¥ ë° í”Œë¡¯
    save_results_and_plots(results)
    
    # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
    print_detailed_results(results)
    
    print("\n" + "="*80)
    print("ë¹„êµ ì™„ë£Œ! ê²°ê³¼ëŠ” ./comprehensive_results/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("="*80)

if __name__ == "__main__":
    main()